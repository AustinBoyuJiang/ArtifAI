# ArtifAI Detector

## Description
The ArtifAI Detector is the first installment in the "AI Drawing Insights" series, designed to discern whether a piece of artwork was created by a human or generated by AI. It is dedicated to addressing copyright and rights issues pertaining to images between humans and AI.


## Task Completions

**2023-09-10** | Initiated the project.

**2023-09-18** | Completed the task of crawling image URLs from ArtStation.

**2023-10-31** | Accomplished the task of downloading images from URLs and logging their status in a local JSON file for future reference.


## Ongoing Tasks:

* Reformating the json file

* Developing the code for data processing.

* Finalizing the main control file to categorize downloaded images as either 'created with AI' or 'not created with AI'.

* Partitioning the data into two sets: one for training and the other for testing.

* Training the AI model and additional related tasks.

## Project Roadmap

### Data Collection
Gather a substantial dataset of drawings. This dataset should have labeled examples of both human-drawn and AI-generated drawings.
Make sure the dataset is balanced to avoid biasing your model towards one class.

### Preprocessing
Normalize the images to have the same size and pixel intensity range.
Augment the dataset to include rotated, scaled, and transformed versions of the drawings to increase the diversity and robustness of your training data.

### Feature Extraction
Manual Feature Engineering: Consider features that might differentiate human from AI drawings such as imperfections, patterns, strokes, and noise.
Use pre-trained neural networks like VGG, ResNet, or MobileNet to extract high-level features from the drawings.

### Model Selection
Start with traditional machine learning models (like SVM, Random Forest) if you have manually engineered features.
For high-level features or raw data, deep learning models like CNNs are more suitable. CNNs can inherently handle image data and extract complex patterns.

### Training
Split the dataset into training, validation, and test sets.
Train the model on the training set, monitor its performance on the validation set, and adjust hyperparameters accordingly.
Regularize the model to avoid overfitting, using techniques such as dropout or L2 regularization for deep models.

### Evaluation
Evaluate the model's performance on the test set. Metrics such as accuracy, precision, recall, and F1-score can be useful.
Consider plotting a confusion matrix to understand the type of errors your model makes.

### Refinement
Based on the evaluation results, refine your model. This could involve gathering more data, tweaking the model architecture, or trying out different algorithms.
Consider using techniques like ensemble learning to potentially boost performance.

### Deployment
Once satisfied with the model's performance, deploy it as a service or integrate it into your software.
Keep in mind that real-world data can be different, so continuously monitor your model's performance.

### Continuous Learning
If possible, set up a feedback loop where users can correct the model's predictions. This new data can be used to retrain and improve your model over time.
Periodically retrain your model to ensure it stays updated, especially if newer versions of AI-generated drawings emerge.

### Ethical Considerations
Ensure that the use of this software respects users' privacy and copyrights.
Always communicate the purpose and potential limitations of the software to its users.