# ArtifAI Detector

## Project Description
The ArtifAI Detector is the first installment in the "AI Drawing Insights" series, designed to discern whether a piece of artwork was created by a human or generated by AI. It is dedicated to addressing copyright and rights issues pertaining to images between humans and AI.


## Development Log

**2023-09-10**
* Project Inception.

**2023-09-18**
* Achieved successful extraction of image URLs from ArtStation through advanced web crawling techniques.

**2023-10-31**
* Executed proficient image retrieval from designated URLs, ensuring efficient and accurate data acquisition.

* Pioneered the implementation of a local JSON database, establishing a robust system for meticulous tracking and future utilization of collected data.

**2023-11-09**
* Undertook a comprehensive reformatting of the JSON file to enhance data structure and readability.

* Executed a thorough reorganization of the data collection program, aiming for increased efficiency and user-friendliness.

**2023-11-12** 
* Standardized image sizes to 256x256 for optimal balance between detail retention and computational efficiency.

* Established train_size or training_size as variable names for the training-to-testing data ratio.

* Explored various image storage formats and decided on using the .npy format for its efficiency in machine learning operations.

* Initiated the development of the training program for the AI image classification project, targeting efficient data handling and model training strategies.

* Implemented a data batch loading mechanism to manage large image datasets effectively, overcoming the limitations of computer memory capacity.

* Revised the Python training program to incorporate dynamic data loading, significantly reducing memory usage during model training.

* Enhanced the data loading function to ensure consistency across images, including converting grayscale images to a uniform three-channel RGB format.

* Implemented functionality for saving the trained model to a local file, facilitating model preservation and future usage.

* Accomplished the first training of the AI model using a dataset of more than 6000 images, yielding an accuracy of 71.23% on the testing set. This promising result highlights the model's capability in differentiating between AI-generated and human-created images. However, there is a potential concern regarding overfitting, which will be a focus for further investigation and model optimization in subsequent development phases.


## Ongoing Tasks

* Compressing and optimizing data size.

* Investigating and addressing the potential overfitting issue in the AI model to improve its generalization capabilities. This includes experimenting with model architecture adjustments, regularization techniques, and data augmentation strategies.

* Training the AI model and executing additional related tasks.

* Deploying the website.


## Challenges Encountered

1. Encountered constraints in harvesting image data from ArtStation in adherence to robots.txt protocols.

    **Solution** | Employed the Selenium framework to emulate authentic user interactions, thereby ensuring compliance while effectively extracting data.

2. Faced issues with inconsistent shapes of image data, leading to errors during the model training process.

    **Solution** | Standardized all images to have a uniform shape of (256,256,3). This involved converting grayscale images into three-channel RGB format, ensuring consistency across the dataset and smooth model training.

3. Exceeded memory limits during data processing and model training.

    **Solution** | Addressed this issue by implementing data batch loading and reducing batch sizes, thereby optimizing memory usage and ensuring efficient processing.

4. Successfully trained the AI model on a dataset of over 6000 images, but observed a potential overfitting issue, as indicated by a 71.23% accuracy rate on the testing set. This suggests a need for careful evaluation and refinement of the model to ensure it generalizes well to unseen data.


## Future Features
分类置信度：除了简单的概率，您还可以提供关于模型对其预测置信度的额外信息，例如置信区间或置信度评分。

解释性反馈：提供一些解释性反馈，说明为什么模型认为图像属于某个类别。这可以通过突出显示图像中对分类决策最有贡献的部分（例如，使用热力图）来实现。

相似案例展示：显示与上传图像类似的、模型已分类的其他图像案例，这有助于用户理解模型的判断基准。

建议和提示：如果模型无法高置信度地分类某图像，您可以提供一些建议或提示，例如建议上传更高质量或不同类型的图像。

用户交互选项：提供一个选项，让用户对模型的分类结果提供反馈。这不仅可以帮助提升用户体验，还可以作为未来改进模型的宝贵数据来源。

附加信息：如果可能的话，提供关于图像分类的额外信息，比如分类类别的简要描述，或者与类别相关的有趣事实。

多种分类结果：在一些情况下，提供排名前几的分类结果可能会很有帮助，特别是当模型对于最高概率的分类不是非常有信心时。

图像处理建议：如果适用，提供一些关于如何改善图像以获得更准确分类的建议（例如，改变光照条件、角度等）。


## Project Roadmap

### Data Collection
Gather a substantial dataset of drawings. This dataset should have labeled examples of both human-drawn and AI-generated drawings.
Make sure the dataset is balanced to avoid biasing your model towards one class.

### Preprocessing
Normalize the images to have the same size and pixel intensity range.
Augment the dataset to include rotated, scaled, and transformed versions of the drawings to increase the diversity and robustness of your training data.

### Feature Extraction
Manual Feature Engineering: Consider features that might differentiate human from AI drawings such as imperfections, patterns, strokes, and noise.
Use pre-trained neural networks like VGG, ResNet, or MobileNet to extract high-level features from the drawings.

### Model Selection
Start with traditional machine learning models (like SVM, Random Forest) if you have manually engineered features.
For high-level features or raw data, deep learning models like CNNs are more suitable. CNNs can inherently handle image data and extract complex patterns.

### Training
Split the dataset into training, validation, and test sets.
Train the model on the training set, monitor its performance on the validation set, and adjust hyperparameters accordingly.
Regularize the model to avoid overfitting, using techniques such as dropout or L2 regularization for deep models.

### Evaluation
Evaluate the model's performance on the test set. Metrics such as accuracy, precision, recall, and F1-score can be useful.
Consider plotting a confusion matrix to understand the type of errors your model makes.

### Refinement
Based on the evaluation results, refine your model. This could involve gathering more data, tweaking the model architecture, or trying out different algorithms.
Consider using techniques like ensemble learning to potentially boost performance.

### Deployment
Once satisfied with the model's performance, deploy it as a service or integrate it into your software.
Keep in mind that real-world data can be different, so continuously monitor your model's performance.

### Outreach and Engagement
To enhance the project's visibility and impact, we will implement a targeted outreach and engagement strategy. Our focus will be on establishing connections with art schools, universities, and professional art platforms such as ArtStation and Pixiv. By showcasing the ArtifAI Detector at educational institutions and on renowned art platforms, we aim to educate and empower artists and creators in distinguishing between human-created and AI-generated art. This initiative will involve workshops, presentations, and collaborations that highlight the tool's utility in preserving the integrity of artistic creation. Through these efforts, we aspire to foster a community of informed users who value the authenticity and originality of human artistry.

### Continuous Learning
If possible, set up a feedback loop where users can correct the model's predictions. This new data can be used to retrain and improve your model over time.
Periodically retrain your model to ensure it stays updated, especially if newer versions of AI-generated drawings emerge.

### Ethical Considerations
Ensure that the use of this software respects users' privacy and copyrights.
Always communicate the purpose and potential limitations of the software to its users.